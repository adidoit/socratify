# Senior Data Engineer - Databricks

**Source URL:** https://databricks.com/company/careers

**Location:** San Francisco, CA | Seattle, WA | Amsterdam, Netherlands  
**Experience:** 4-7 years  
**Salary:** $180,000 - $320,000 + equity + bonuses

**Role Overview:**
Build next-generation data lakehouse platform serving enterprise customers. Focus on unified analytics and machine learning infrastructure.

**Key Responsibilities:**
- Develop Apache Spark optimizations for petabyte-scale data processing
- Build Delta Lake storage layer for ACID transactions and time travel
- Design MLflow integration for end-to-end machine learning lifecycle management
- Implement auto-scaling infrastructure for unpredictable customer workloads
- Support Fortune 500 customer migrations from traditional data warehouses

**Technical Requirements:**
- Expert-level knowledge of Apache Spark and distributed computing
- Strong programming skills in Scala, Python, and Java
- Experience with cloud platforms (AWS, Azure, GCP) and Kubernetes
- Deep understanding of data formats (Parquet, Delta, Iceberg)
- Knowledge of machine learning operations and model deployment

**Preferred Qualifications:**
- Contributions to open-source projects (Spark, Delta Lake, MLflow)
- Experience with customer-facing roles and technical consulting
- Background in distributed systems and database internals